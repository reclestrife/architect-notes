
# MapReduce Introduction

https://pdos.csail.mit.edu/6.824/notes/l01.txt

## MindMap

- The problem
  - Solution
  - Example
- Benifits
- Limitations
- Implementation
  - implementation details
  - chanllenges and solutions
    - network usage
    - balancing the work
    - fault tolenrence
- Current status
  - Conclusion

## Background

### The problem

- Heavy computation task on large datasets, such as, build search index of the web
- Help programmers which are not distributed system experts, just define map and reduce functions as sequential code
- MapReduce framework handle and hide distribution complexities

#### Solution

1. Input is already split into M files
2. MR calls __map__ function on each input file and produces intermediate key-values
3. MR gathers all result with same key and calls __reduce__ function
4. Final result is produced by __reduce__ function with aggregation of same key

#### Example

Word counting problem.

### Benifits

- __map__ and __reduce__ functions both can run in parallel, so scalability is good
- MR hides many details:
  - sending app code to servers
  - tracking which task is done
  - moving data from mapper to reducers
  - balancing loads
  - recovering from failures

### Limitations

- No interactions or states
- No iterations or multi-stage pipelines (but result of one MR could be input of another MR)
- No real-time or streaming processing (only batches)

## Implementation

### Implementation details

1. One master that hands out tasks to workers and remembers progress
2. Master gives Map tasks to workers until all Maps complete
3. Master hands out work to Reduce, then generates result

### Chanllenges and solutions

__Network usage__
- MR needs huge parallel input output throughput, using GFS is a big win
- Run MR and GFS on same server, so input could from local disk
- Reduce reads result from Map directly
- Network could be a bottleneck, but today: networks and root switches are much faster relative to CPU/disk.

__Load balance__
- More tasks than workers
- Faster workers can finish more tasks
- Avoid waiting for the slowest-n server

__Fault tolerence__
- MR re-runs just the failed Map()s and Reduce()s.
- So Map and Reduce must be pure deterministic functions: 
  - they are only allowed to look at their arguments.
  - no state, no file I/O, no interaction, no external communication.
- What if the master crashes

## Current status
  Hugely influential (Hadoop, Spark, &c).
  Probably no longer in use at Google.
    Replaced by Flume / FlumeJava (see paper by Chambers et al).
    GFS replaced by Colossus (no good description), and BigTable.

### Conclusion

MapReduce single-handedly made big cluster computation popular.
- Not the most efficient or flexible.
- Scales well.
- Easy to program -- failures and data movement are hidden.